#!/usr/bin/env zsh

# AI Command Line Helper using Ollama
# Usage: ai-helper [model_name] or source this file and use 'ai' function

# Default model - can be overridden by environment variable or command line argument
DEFAULT_MODEL="${OLLAMA_MODEL:-llama3.2}"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to check if ollama is installed and running
check_ollama() {
    if ! command -v ollama &> /dev/null; then
        echo -e "${RED}Error: Ollama is not installed or not in PATH${NC}"
        echo "Please install Ollama from https://ollama.ai"
        return 1
    fi
    
    # Check if ollama service is running
    if ! ollama list &> /dev/null; then
        echo -e "${YELLOW}Warning: Ollama service might not be running${NC}"
        echo "Try running: ollama serve"
        return 1
    fi
    
    return 0
}

# Function to get recent command history
get_command_history() {
    # Get last 20 commands from current session, excluding the ai helper calls
    # Handle case where there's no history available
    local history_output
    history_output=$(fc -l -20 2>/dev/null | grep -v "ai " | grep -v "ai-helper" | tail -10 2>/dev/null)
    
    if [ -z "$history_output" ]; then
        echo "No recent command history available"
    else
        echo "$history_output"
    fi
}

# Function to generate command using Ollama
generate_command() {
    local prompt="$1"
    local model="$2"
    local history="$3"
    
    # Create the system prompt
    local system_prompt="You are a helpful command line assistant. Generate the exact terminal command(s) needed to accomplish the user's request. 

Rules:
- If multiple commands are needed, put each command on a separate line
- Do not include explanations, markdown formatting, or any other text
- Only output the raw commands that can be executed directly in a terminal
- For complex tasks requiring multiple steps, provide all necessary commands in sequence

Context: The user is on macOS (darwin) using zsh shell.

Recent command history for context:
$history

User request: $prompt

Respond with ONLY the command(s), one per line, nothing else."

    # Call Ollama API
    local response=$(ollama run "$model" "$system_prompt" 2>/dev/null)
    
    if [ $? -ne 0 ]; then
        echo -e "${RED}Error: Failed to get response from Ollama${NC}"
        return 1
    fi
    
    # Clean up the response - remove any potential markdown or extra formatting
    echo "$response" | sed 's/```.*//g' | sed 's/`//g' | sed '/^[[:space:]]*$/d'
}

# Function to parse and handle multiple commands
parse_and_execute_commands() {
    local commands_text="$1"
    local -a commands
    
    # Split commands into array, handling both newlines and semicolons
    while IFS= read -r line; do
        # Skip empty lines
        if [[ -n "${line// }" ]]; then
            # Split by semicolon if present
            if [[ "$line" == *";"* ]]; then
                local -a split_commands
                split_commands=(${(s/;/)line})
                for cmd in "${split_commands[@]}"; do
                    cmd=$(echo "$cmd" | xargs)  # trim whitespace
                    if [[ -n "$cmd" ]]; then
                        commands+=("$cmd")
                    fi
                done
            else
                commands+=("$line")
            fi
        fi
    done <<< "$commands_text"
    
    # If no commands found, return error
    if [ ${#commands} -eq 0 ]; then
        echo -e "${RED}Error: No valid commands found${NC}"
        return 1
    fi
    
    # Display all commands first
    echo -e "${BLUE}Generated command(s):${NC}"
    for i in {1..${#commands}}; do
        echo -e "${GREEN}$i. ${commands[i]}${NC}"
    done
    echo
    
    # If only one command, use simple confirmation
    if [ ${#commands} -eq 1 ]; then
        echo -n -e "${YELLOW}Execute this command? [y/N]: ${NC}"
        read -r response
        
        case "$response" in
            [yY]|[yY][eE][sS])
                echo -e "${GREEN}Executing...${NC}"
                eval "${commands[1]}"
                ;;
            *)
                echo -e "${YELLOW}Command not executed.${NC}"
                ;;
        esac
        return 0
    fi
    
    # Multiple commands - offer options
    echo -e "${YELLOW}Multiple commands detected. Choose an option:${NC}"
    echo "  [a] Execute all commands in sequence"
    echo "  [s] Execute commands one by one (with individual confirmation)"
    echo "  [n] Don't execute any commands"
    echo
    echo -n -e "${YELLOW}Your choice [a/s/N]: ${NC}"
    read -r choice
    
    case "$choice" in
        [aA])
            echo -e "${GREEN}Executing all commands...${NC}"
            for i in {1..${#commands}}; do
                echo -e "${BLUE}Executing command $i: ${commands[i]}${NC}"
                eval "${commands[i]}"
                if [ $? -ne 0 ]; then
                    echo -e "${RED}Command $i failed. Stopping execution.${NC}"
                    return 1
                fi
                echo
            done
            ;;
        [sS])
            echo -e "${GREEN}Executing commands with individual confirmation...${NC}"
            for i in {1..${#commands}}; do
                echo -e "${BLUE}Command $i: ${commands[i]}${NC}"
                echo -n -e "${YELLOW}Execute this command? [y/N/q]: ${NC}"
                read -r response
                
                case "$response" in
                    [yY]|[yY][eE][sS])
                        echo -e "${GREEN}Executing...${NC}"
                        eval "${commands[i]}"
                        if [ $? -ne 0 ]; then
                            echo -e "${RED}Command failed.${NC}"
                        fi
                        ;;
                    [qQ])
                        echo -e "${YELLOW}Stopping execution.${NC}"
                        return 0
                        ;;
                    *)
                        echo -e "${YELLOW}Skipping command.${NC}"
                        ;;
                esac
                echo
            done
            ;;
        *)
            echo -e "${YELLOW}No commands executed.${NC}"
            ;;
    esac
}

# Main AI helper function
ai() {
    local model="$DEFAULT_MODEL"
    local prompt=""
    
    # Parse arguments
    if [ $# -eq 0 ]; then
        echo -e "${YELLOW}Usage: ai [model_name] <prompt>${NC}"
        echo -e "${YELLOW}   or: ai <prompt>${NC}"
        echo -e "${YELLOW}Current model: $model${NC}"
        return 1
    fi
    
    # Check if first argument is a model name (check if it exists in ollama list)
    if [ $# -gt 1 ] && [[ "$1" =~ ^[a-zA-Z0-9._:-]+$ ]] && ollama list | grep -q "^$1"; then
        model="$1"
        shift
        prompt="$*"
    else
        prompt="$*"
    fi
    
    if [ -z "$prompt" ]; then
        echo -e "${RED}Error: No prompt provided${NC}"
        return 1
    fi
    
    # Check ollama availability
    if ! check_ollama; then
        return 1
    fi
    
    echo -e "${BLUE}Using model: $model${NC}"
    echo -e "${BLUE}Prompt: $prompt${NC}"
    echo
    
    # Get command history
    local history=$(get_command_history)
    
    # Generate command
    echo -e "${YELLOW}Generating command(s)...${NC}"
    local generated_command=$(generate_command "$prompt" "$model" "$history")
    
    if [ $? -ne 0 ] || [ -z "$generated_command" ]; then
        echo -e "${RED}Error: Failed to generate command${NC}"
        return 1
    fi
    
    # Parse and execute commands
    parse_and_execute_commands "$generated_command"
}

# Main execution logic
main() {
    # Parse command line arguments for direct execution
    if [ $# -eq 0 ]; then
        echo -e "${YELLOW}AI Command Line Helper${NC}"
        echo -e "${YELLOW}Usage: $SCRIPT_NAME [model_name] <prompt>${NC}"
        echo -e "${YELLOW}   or: source $SCRIPT_NAME and use 'ai' function${NC}"
        echo -e "${YELLOW}Current default model: $DEFAULT_MODEL${NC}"
        echo
        echo -e "${YELLOW}Examples:${NC}"
        echo -e "  $SCRIPT_NAME kill the process using port 8080"
        echo -e "  $SCRIPT_NAME llama3.1 find all .js files modified in last 24 hours"
        echo -e "  $SCRIPT_NAME create a backup directory and copy all .txt files to it"
        echo -e "  source $SCRIPT_NAME && ai list all docker containers"
        return 1
    fi
    
    # Run the ai function with all arguments
    ai "$@"
}

# If script is being run directly (not sourced)
if [[ "$ZSH_EVAL_CONTEXT" == "toplevel" ]]; then
    # Store script name for use in help text
    SCRIPT_NAME="$0"
    # Run main function with all arguments
    main "$@"
else
    # Script is being sourced
    echo -e "${GREEN}AI Command Line Helper loaded!${NC}"
    echo -e "${YELLOW}Usage: ai [model_name] <prompt>${NC}"
    echo -e "${YELLOW}Current default model: $DEFAULT_MODEL${NC}"
    echo -e "${YELLOW}Set OLLAMA_MODEL environment variable to change default model${NC}"
fi 